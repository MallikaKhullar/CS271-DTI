{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.getcwd() + '\\\\..')\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from operator import itemgetter\n",
    "\n",
    "class CNNModel1(nn.Module):\n",
    "    def __init__(self, fully_layer_1, fully_layer_2, drop_rate):\n",
    "        super(CNNModel1, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 32, 2)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 2)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 2)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 64, 2)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.conv5 = nn.Conv2d(64, 32, 2)\n",
    "        self.bn5 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.drop_rate = drop_rate\n",
    "        self.fc1 = nn.Linear(32*5*5, fully_layer_1)\n",
    "        self.fc2 = nn.Linear(fully_layer_1, fully_layer_2)\n",
    "        self.fc3 = nn.Linear(fully_layer_2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         print(x.shape)\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "#         Â print(x.shape)\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "#         print(x.shape)\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "#         print(x.shape)\n",
    "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
    "#         print(x.shape)\n",
    "        x = self.pool(F.relu(self.bn5(self.conv5(x))))\n",
    "#         print(x.shape)\n",
    "\n",
    "        x = x.view(-1, 32*5*5)\n",
    "        x = F.dropout(F.relu(self.fc1(x)), self.drop_rate)\n",
    "        x = F.dropout(F.relu(self.fc2(x)), self.drop_rate)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# TODO: Create other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from data_processing import get_train_test_val_data_loaders\n",
    "from evaluation_metrics import prec_rec_f1_acc_mcc, get_list_of_scores\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "torch.manual_seed(123)\n",
    "np.random.seed(123)\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "project_file_path = \"{}DEEPScreen\".format(os.getcwd().split(\"DEEPScreen\")[0])\n",
    "training_files_path = \"{}/training_files\".format(project_file_path)\n",
    "result_files_path = \"{}/result_files\".format(project_file_path)\n",
    "trained_models_path = \"{}/trained_models\".format(project_file_path)\n",
    "\n",
    "# training_files_path = \"training_files\"\n",
    "# result_files_path = \"result_files\"\n",
    "# trained_models_path = \"trained_models\"\n",
    "\n",
    "\n",
    "def save_best_model_predictions(experiment_name, epoch, validation_scores_dict, test_scores_dict, model, project_file_path, target_id, str_arguments,\n",
    "                                                                                   all_test_comp_ids, test_labels, test_predictions):\n",
    "\n",
    "    if not os.path.exists(os.path.join(trained_models_path, experiment_name)):\n",
    "        os.makedirs(os.path.join(trained_models_path, experiment_name))\n",
    "\n",
    "    torch.save(model.state_dict(),\n",
    "               \"{}/{}/{}_best_val-{}-state_dict.pth\".format(trained_models_path, experiment_name,\n",
    "                                                                               target_id, str_arguments))\n",
    "    # print(all_test_comp_ids)\n",
    "    str_test_predictions = \"CompoundID\\tLabel\\tPred\\n\"\n",
    "    for ind in range(len(all_test_comp_ids)):\n",
    "        str_test_predictions += \"{}\\t{}\\t{}\\n\".format(all_test_comp_ids[ind],\n",
    "                                                          test_labels[ind],\n",
    "                                                          test_predictions[ind])\n",
    "    best_test_performance_dict = test_scores_dict\n",
    "    best_test_predictions = str_test_predictions\n",
    "    return validation_scores_dict, best_test_performance_dict, best_test_predictions, str_test_predictions\n",
    "\n",
    "\n",
    "\n",
    "def get_device():\n",
    "    device = \"cpu\"\n",
    "    if use_gpu:\n",
    "        print(\"GPU is available on this device!\")\n",
    "        device = \"cuda\"\n",
    "    else:\n",
    "        print(\"CPU is available on this device!\")\n",
    "    return device\n",
    "\n",
    "\n",
    "def calculate_val_test_loss(model, criterion, data_loader, device):\n",
    "    total_count = 0\n",
    "    total_loss = 0.0\n",
    "    all_comp_ids = []\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    for i, data in enumerate(data_loader):\n",
    "        img_arrs, labels, comp_ids = data\n",
    "        img_arrs, labels = torch.tensor(img_arrs).type(torch.FloatTensor).to(device), torch.tensor(labels).to(device)\n",
    "        total_count += len(comp_ids)\n",
    "        y_pred = model(img_arrs).to(device)\n",
    "        loss = criterion(y_pred.squeeze(), labels)\n",
    "        total_loss += float(loss.item())\n",
    "        all_comp_ids.extend(list(comp_ids))\n",
    "        _, preds = torch.max(y_pred, 1)\n",
    "        all_labels.extend(list(labels))\n",
    "        all_predictions.extend(list(preds))\n",
    "\n",
    "\n",
    "    return total_loss, total_count, all_comp_ids, all_labels, all_predictions\n",
    "\n",
    "\n",
    "def train_validation_test_training(target_id, model_name, fully_layer_1, fully_layer_2, learning_rate, batch_size, drop_rate, n_epoch, experiment_name):\n",
    "    arguments = [str(argm) for argm in\n",
    "                 [target_id, model_name, fully_layer_1, fully_layer_2, learning_rate, batch_size, drop_rate, n_epoch, experiment_name]]\n",
    "\n",
    "    str_arguments = \"-\".join(arguments)\n",
    "    print(\"Arguments:\", str_arguments)\n",
    "\n",
    "    device = get_device()\n",
    "    exp_path = os.path.join(result_files_path, \"experiments\", experiment_name)\n",
    "\n",
    "    if not os.path.exists(exp_path):\n",
    "        os.makedirs(exp_path)\n",
    "\n",
    "    best_val_test_result_fl = open(\n",
    "        \"{}/best_val_test_performance_results-{}.txt\".format(exp_path,str_arguments), \"w\")\n",
    "    best_val_test_prediction_fl = open(\n",
    "        \"{}/best_val_test_predictions-{}.txt\".format(exp_path,str_arguments), \"w\")\n",
    "\n",
    "#     print(\"BEST F1\", best_val_test_result_fl, best_val_test_prediction_fl)\n",
    "#     print(\"Fetching train loader\")\n",
    "    train_loader, valid_loader, test_loader = get_train_test_val_data_loaders(target_id, batch_size)\n",
    "    \n",
    "#     print(train_loader, valid_loader, test_loader)\n",
    "    \n",
    "    model = None\n",
    "    \n",
    "    if model_name == \"CNNModel1\":\n",
    "        model = CNNModel1(fully_layer_1, fully_layer_2, drop_rate).to(device)\n",
    "        \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    best_val_mcc_score, best_test_mcc_score = 0.0, 0.0\n",
    "    best_val_test_performance_dict = dict()\n",
    "    best_val_test_performance_dict[\"MCC\"] = 0.0\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        total_training_count = 0\n",
    "        total_training_loss = 0.0\n",
    "        print(\"Epoch :{}\".format(epoch))\n",
    "        model.train()\n",
    "        batch_number = 0\n",
    "        all_training_labels = []\n",
    "        all_training_preds = []\n",
    "        print(\"Training mode:\", model.training)\n",
    "        for i, data in enumerate(train_loader):\n",
    "#             print(i, len(data))\n",
    "            batch_number += 1\n",
    "            # print(batch_number)\n",
    "            # clear gradient DO NOT forget you fool!\n",
    "            optimizer.zero_grad()\n",
    "            img_arrs, labels, comp_ids = data\n",
    "            img_arrs, labels = torch.tensor(img_arrs).type(torch.FloatTensor).to(device), torch.tensor(labels).to(device)\n",
    "\n",
    "            total_training_count += len(comp_ids)\n",
    "            y_pred = model(img_arrs).to(device)\n",
    "            _, preds = torch.max(y_pred, 1)\n",
    "            all_training_labels.extend(list(labels))\n",
    "            all_training_preds.extend(list(preds))\n",
    "\n",
    "            loss = criterion(y_pred.squeeze(), labels)\n",
    "            total_training_loss += float(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\"Epoch {} training loss:\".format(epoch), total_training_loss)\n",
    "        training_perf_dict = dict()\n",
    "        try:\n",
    "            training_perf_dict = prec_rec_f1_acc_mcc(all_training_labels, all_training_preds)\n",
    "        except:\n",
    "            print(\"There was a problem during training performance calculation!\")\n",
    "        # print(training_perf_dict)\n",
    "        model.eval()\n",
    "        with torch.no_grad():  # torch.set_grad_enabled(False):\n",
    "            print(\"Validation mode:\", not model.training)\n",
    "\n",
    "            total_val_loss, total_val_count, all_val_comp_ids, all_val_labels, val_predictions = calculate_val_test_loss(model, criterion, valid_loader, device)\n",
    "            \n",
    "            val_perf_dict = dict()\n",
    "            val_perf_dict[\"MCC\"] = 0.0\n",
    "            try:\n",
    "                val_perf_dict = prec_rec_f1_acc_mcc(all_val_labels, val_predictions)\n",
    "            except:\n",
    "                print(\"There was a problem during validation performance calculation!\")\n",
    "            \n",
    "\n",
    "            total_test_loss, total_test_count, all_test_comp_ids, all_test_labels, test_predictions = calculate_val_test_loss(\n",
    "                model, criterion, test_loader, device)\n",
    "            \n",
    "            test_perf_dict = dict()\n",
    "            test_perf_dict[\"MCC\"] = 0.0\n",
    "            try:\n",
    "                test_perf_dict = prec_rec_f1_acc_mcc(all_test_labels, test_predictions)\n",
    "            except:\n",
    "                print(\"There was a problem during test performance calculation!\")\n",
    "\n",
    "            if val_perf_dict[\"MCC\"] > best_val_mcc_score and test_perf_dict[\"MCC\"]> best_test_mcc_score:\n",
    "                best_val_mcc_score = val_perf_dict[\"MCC\"]\n",
    "                best_test_mcc_score = test_perf_dict[\"MCC\"]\n",
    "\n",
    "                validation_scores_dict, best_test_performance_dict, best_test_predictions, str_test_predictions = save_best_model_predictions(\n",
    "                    experiment_name, epoch, val_perf_dict, test_perf_dict,\n",
    "                    model,project_file_path, target_id, str_arguments,\n",
    "                    all_test_comp_ids, all_test_labels, test_predictions)\n",
    "\n",
    "        if epoch == n_epoch - 1:\n",
    "            score_list = get_list_of_scores()\n",
    "            print(\"Training scores: {}\\n\\nValidation scores: {}\\n\".format(training_perf_dict, val_perf_dict))\n",
    "#             for scr in score_list:\n",
    "#                 best_val_test_result_fl.write(\"Test {}:\\t{}\\n\".format(scr, best_test_performance_dict[scr]))\n",
    "#             best_val_test_prediction_fl.write(best_test_predictions)\n",
    "#             best_val_test_result_fl.close()\n",
    "#             best_val_test_prediction_fl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arguments: CHEMBL286-CNNModel1-512-256-0.001-32-0.25-10-my_experiment\n",
      "CPU is available on this device!\n",
      "/Users/mallikapriyakhullar/Documents/Stanford/Q4/CS271/DEEPScreen/training_files/target_training_datasets/CHEMBL286\n",
      "/Users/mallikapriyakhullar/Documents/Stanford/Q4/CS271/DEEPScreen/training_files/target_training_datasets/CHEMBL286\n",
      "/Users/mallikapriyakhullar/Documents/Stanford/Q4/CS271/DEEPScreen/training_files/target_training_datasets/CHEMBL286\n",
      "Epoch :0\n",
      "Training mode: True\n",
      "Epoch 0 training loss: 0.6853883266448975\n",
      "Validation mode: True\n",
      "Epoch :1\n",
      "Training mode: True\n",
      "Epoch 1 training loss: 0.719788134098053\n",
      "Validation mode: True\n",
      "Epoch :2\n",
      "Training mode: True\n",
      "Epoch 2 training loss: 0.6567627191543579\n",
      "Validation mode: True\n",
      "Epoch :3\n",
      "Training mode: True\n",
      "Epoch 3 training loss: 0.48886221647262573\n",
      "Validation mode: True\n",
      "Epoch :4\n",
      "Training mode: True\n",
      "Epoch 4 training loss: 0.5156181454658508\n",
      "Validation mode: True\n",
      "Epoch :5\n",
      "Training mode: True\n",
      "Epoch 5 training loss: 0.48656800389289856\n",
      "Validation mode: True\n",
      "Epoch :6\n",
      "Training mode: True\n",
      "Epoch 6 training loss: 0.561801016330719\n",
      "Validation mode: True\n",
      "Epoch :7\n",
      "Training mode: True\n",
      "Epoch 7 training loss: 0.6743931174278259\n",
      "Validation mode: True\n",
      "Epoch :8\n",
      "Training mode: True\n",
      "Epoch 8 training loss: 0.468963623046875\n",
      "Validation mode: True\n",
      "Epoch :9\n",
      "Training mode: True\n",
      "Epoch 9 training loss: 0.3352351784706116\n",
      "Validation mode: True\n",
      "Training scores: {'Precision': 1.0, 'Recall': 0.75, 'F1-Score': 0.8571428571428571, 'Accuracy': 0.9090909090909091, 'MCC': 0.8100925873009825, 'TP': 3, 'FP': 0, 'TN': 7, 'FN': 1}\n",
      "\n",
      "Validation scores: {'Precision': 0.0, 'Recall': 0.0, 'F1-Score': 0.0, 'Accuracy': 0.4444444444444444, 'MCC': -0.31622776601683794, 'TP': 0, 'FP': 1, 'TN': 4, 'FN': 4}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_validation_test_training(\"CHEMBL286\", \"CNNModel1\", 512, 256, 0.001, 32,\n",
    "                               0.25, 10, \"my_experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
