{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cairosvg\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/8a/1dd6751941e407a4c0ea82a72143d8cfee5d56338bc13c586b1223d8b3ab/CairoSVG-2.5.0-py3-none-any.whl (45kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 1.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: defusedxml in /Users/mallikapriyakhullar/anaconda3/lib/python3.7/site-packages (from cairosvg) (0.6.0)\n",
      "Collecting cairocffi (from cairosvg)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/ca/0bffed5116d21251469df200448667e90acaa5131edea869b44a3fbc73d0/cairocffi-1.2.0.tar.gz (70kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 1.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cssselect2 (from cairosvg)\n",
      "  Downloading https://files.pythonhosted.org/packages/99/da/c86ec74495c69518720652f8aa8ab642d8af61a2098eede9db8b03d3c8b4/cssselect2-0.4.1-py3-none-any.whl\n",
      "Requirement already satisfied: pillow in /Users/mallikapriyakhullar/anaconda3/lib/python3.7/site-packages (from cairosvg) (6.1.0)\n",
      "Collecting tinycss2 (from cairosvg)\n",
      "  Downloading https://files.pythonhosted.org/packages/65/f7/63bf697a7c7257d304269b49f1be3dfe429856889e93963d6f5790d77d82/tinycss2-1.1.0-py3-none-any.whl\n",
      "Requirement already satisfied: cffi>=1.1.0 in /Users/mallikapriyakhullar/anaconda3/lib/python3.7/site-packages (from cairocffi->cairosvg) (1.12.3)\n",
      "Requirement already satisfied: webencodings in /Users/mallikapriyakhullar/anaconda3/lib/python3.7/site-packages (from cssselect2->cairosvg) (0.5.1)\n",
      "Requirement already satisfied: pycparser in /Users/mallikapriyakhullar/anaconda3/lib/python3.7/site-packages (from cffi>=1.1.0->cairocffi->cairosvg) (2.19)\n",
      "Building wheels for collected packages: cairocffi\n",
      "  Building wheel for cairocffi (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/mallikapriyakhullar/Library/Caches/pip/wheels/40/76/48/f1effadceea83b32e7d957dd0f92db4db8b537d7b72b4ef374\n",
      "Successfully built cairocffi\n",
      "Installing collected packages: cairocffi, tinycss2, cssselect2, cairosvg\n",
      "Successfully installed cairocffi-1.2.0 cairosvg-2.5.0 cssselect2-0.4.1 tinycss2-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install cairosvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unknown locale: UTF-8",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4f0a4c56ef68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfingerprintProcessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgetSMILEsFromFileWithHeader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetActInactListForATarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstructDataMatricesForATarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstructDataMatricesForATargetOtherClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetTopNModels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatthews_corrcoef\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Stanford/Q4/CS271/CS271-DTI/bin/fingerprintProcessing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcairosvg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# from rdkit import Chem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# from rdkit.Chem import Draw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/cairosvg/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# VERSION is used in the \"url\" module imported by \"surface\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msurface\u001b[0m  \u001b[0;31m# noqa isort:skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/cairosvg/surface.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegate_color\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m from .defs import (\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mapply_filter_after_painting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_filter_before_painting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mfilter_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient_or_pattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear_gradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaint_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/cairosvg/defs.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \"\"\"\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbounding_box\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcalculate_bounding_box\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_non_empty_bounding_box\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatch_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mhelpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpaint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/cairosvg/bounding_box.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0macos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misinf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mradians\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatch_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mhelpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPATH_LETTERS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/cairosvg/features.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mROOT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'http://www.w3.org/TR/SVG11/feature'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mLOCALE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetdefaultlocale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m SUPPORTED_FEATURES = frozenset((\n\u001b[1;32m     11\u001b[0m     ROOT + '#' + feature for feature in (\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/locale.py\u001b[0m in \u001b[0;36mgetdefaultlocale\u001b[0;34m(envvars)\u001b[0m\n\u001b[1;32m    566\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0mlocalename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'C'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_parse_localename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocalename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/locale.py\u001b[0m in \u001b[0;36m_parse_localename\u001b[0;34m(localename)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'C'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unknown locale: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlocalename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_build_localename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocaletuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: unknown locale: UTF-8"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from fingerprintProcessing import getSMILEsFromFileWithHeader, getActInactListForATarget, constructDataMatricesForATarget, constructDataMatricesForATargetOtherClassifier, getTopNModels\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from random import shuffle\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sys\n",
    "\n",
    "\n",
    "IMG_SIZE = 200\n",
    "\n",
    "\n",
    "training_dataset_path = \"/Users/trman/OneDrive/Projects/DrugDiscovery/TrainingDatasets\"\n",
    "images_path = \"../images200\"\n",
    "TEMP_IMG_OUTPUT_PATH = \"../tempImage\"\n",
    "\n",
    "import sys\n",
    "\n",
    "def eprint(*args, **kwargs):\n",
    "    print(*args, file=sys.stderr, **kwargs)\n",
    "\n",
    "def constructECFP4FeaturesVectors(target_id):\n",
    "    train_test_data = []\n",
    "    prob_count = 0\n",
    "    count = 0\n",
    "    compound_smiles_dict = getSMILEsFromFileWithHeader(\"chembl_23_chemreps.txt\")\n",
    "    act_list, inact_list = getActInactListForATarget(target_id, \"act_inact_comps_10.0_20.0_chembl_preprocessed_sp_b_pchembl_data_blast_comp_20.txt\")\n",
    "\n",
    "    if len(inact_list) >= len(act_list):\n",
    "        inact_list = inact_list[:len(act_list)]\n",
    "    else:\n",
    "        act_list = act_list[:int(len(inact_list)*1.5)]\n",
    "\n",
    "    act_dict = dict()\n",
    "    inact_dict = dict()\n",
    "    for act_comp in act_list:\n",
    "        act_dict[act_comp] = \"\"\n",
    "\n",
    "    for inact_comp in inact_list:\n",
    "        inact_dict[inact_comp] = \"\"\n",
    "    # ecfp4_fl = open(\"/Users/trman/OneDrive/Projects/BioactivityDataAnalysis/trainingFiles/compound_ecfp4_vectors.tsv\", \"r\")\n",
    "    # lst_ecfp4_fl = ecfp4_fl.read().split(\"\\n\")\n",
    "    # ecfp4_fl.close()\n",
    "    ecfp4_dict = dict()\n",
    "    count = 0\n",
    "\n",
    "    for act_comp in act_dict.keys():\n",
    "        act_smiles = \"\"\n",
    "        try:\n",
    "            act_smiles = compound_smiles_dict[act_comp]\n",
    "        except:\n",
    "            pass\n",
    "        if act_smiles != \"\":\n",
    "            try:\n",
    "\n",
    "                m = Chem.MolFromSmiles(act_smiles)\n",
    "                str_ecfp4 = AllChem.GetMorganFingerprintAsBitVect(m, 2, nBits=1024).ToBitString()\n",
    "                str_ecfp4 = [float(i) for i in str_ecfp4]\n",
    "                ecfp4_dict[act_comp] = str_ecfp4\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n",
    "    for inact_comp in inact_dict.keys():\n",
    "        inact_smiles = \"\"\n",
    "        try:\n",
    "            inact_smiles = compound_smiles_dict[inact_comp]\n",
    "        except:\n",
    "            pass\n",
    "        if inact_smiles != \"\":\n",
    "            try:\n",
    "\n",
    "                m = Chem.MolFromSmiles(inact_smiles)\n",
    "                str_ecfp4 = AllChem.GetMorganFingerprintAsBitVect(m, 2, nBits=1024).ToBitString()\n",
    "                str_ecfp4 = [float(i) for i in str_ecfp4]\n",
    "                ecfp4_dict[inact_comp] = str_ecfp4\n",
    "            except:\n",
    "                pass\n",
    "    # print(len(ecfp4_dict.keys()))\n",
    "    \"\"\"\n",
    "    # using ready-to-use feature vectors\n",
    "    with open(\"/Users/trman/OneDrive/Projects/BioactivityDataAnalysis/trainingFiles/compound_ecfp4_vectors.tsv\") as f:\n",
    "        for ecfp_line in f:\n",
    "            count+= 1\n",
    "            #if count%1000==0:\n",
    "            #    print(count)\n",
    "            ecfp_line = ecfp_line.split(\"\\n\")[0]\n",
    "            comp_id, fp = ecfp_line.split(\"\\t\")\n",
    "            try:\n",
    "                act_dict[comp_id]\n",
    "                fp = [float(i) for i in fp]\n",
    "                ecfp4_dict[comp_id] = fp\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                inact_dict[comp_id]\n",
    "                fp = [float(i) for i in fp]\n",
    "                ecfp4_dict[comp_id] = fp\n",
    "            except:\n",
    "                pass\n",
    "    \"\"\"\n",
    "\n",
    "    # print(\"Number of active compounds :\\t{}\".format(len(act_list)))\n",
    "    # print(\"Number of inactive compounds :\\t{}\".format(len(inact_list)))\n",
    "    train_test_data = []\n",
    "    for pos_comp in act_list:\n",
    "        label = [1, 0]\n",
    "        try:\n",
    "            count += 1\n",
    "            train_test_data.append([np.asarray(ecfp4_dict[pos_comp]), np.array(label), pos_comp])\n",
    "        except:\n",
    "            prob_count += 1\n",
    "            pass\n",
    "\n",
    "    for neg_comp in inact_list:\n",
    "        label = [0, 1]\n",
    "        try:\n",
    "            count += 1\n",
    "            train_test_data.append([np.asarray(ecfp4_dict[neg_comp]), np.array(label), neg_comp])\n",
    "        except:\n",
    "            prob_count += 1\n",
    "            pass\n",
    "    shuffle(train_test_data)\n",
    "    return train_test_data\n",
    "\n",
    "# def copyBestModelLOG(target):\n",
    "#     best_result_fl = open(\"../resultFiles/ChEMBLBestModelResultsAll_v2.txt.txt\", \"r\")\n",
    "#     lst_best_result_fl = best_result_fl.read().split(\"\\n\")\n",
    "#     best_result_fl.close()\n",
    "\n",
    "#     log_fl_name = \"\"\n",
    "#     for line in lst_best_result_fl:\n",
    "#         line = line.split(\"\\t\")\n",
    "#         print(line)\n",
    "#         if line[2]==target:\n",
    "#             log_fl_name = line[0]\n",
    "#             break\n",
    "\n",
    "#     print(log_fl_name)\n",
    "\n",
    "#     log_path = [\"rahmetCLUSTERLOGS\", \"tdoganYODALOGS\"]\n",
    "#     modelTypeLOG = [\"ImageNetLOGS\", \"OtherLOGS\"]\n",
    "\n",
    "\n",
    "#     test_line = \"\"\n",
    "#     for lgp in log_path:\n",
    "#         for mdltype in modelTypeLOG:\n",
    "#             if os.path.exists(\"../resultFiles/LOGS/{}/{}/{}\".format(lgp, mdltype,log_fl_name)):\n",
    "#                 subprocess.call([\"cp\",\"../resultFiles/LOGS/{}/{}/{}\".format(lgp, mdltype,log_fl_name),\"../resultFiles/LOGS/bestModelLOGS\"])\n",
    "\n",
    "# def getTestCompounds(target):\n",
    "\n",
    "#     log_fl_name = getTopNModels(1)[0][target][0][2]\n",
    "\n",
    "#     #print(log_fl_name)\n",
    "\n",
    "#     test_line = \"\"\n",
    "#     log_fl = open(\"../resultFiles/LOGS/bestModelLOGS/{}\".format(log_fl_name),\"r\")\n",
    "#     lst_log_fl = log_fl.read().split(\"\\n\")\n",
    "#     log_fl.close()\n",
    "\n",
    "#     for line in lst_log_fl:\n",
    "#         if \"ACT,\" in line:\n",
    "#             test_line = line\n",
    "#             break\n",
    "\n",
    "#     test_comp_names = []\n",
    "\n",
    "#     test_line = test_line.split(\"\\t\")\n",
    "#     for item in test_line:\n",
    "#         item = item.split(\",\")\n",
    "#         if item[0].startswith(\"CHEMBL\"):\n",
    "#             test_comp_names.append(item[0])\n",
    "#     #print(test_comp_names)\n",
    "#     return test_comp_names\n",
    "\n",
    "\n",
    "# def trainModelTarget(target, rotate=False):\n",
    "#     print(\"1\")\n",
    "#     model = None\n",
    "#     test_comps = [\"CHEMBL63965\"]\n",
    "#     # print(test_comps)\n",
    "#     print(\"2\")\n",
    "#     train = constructDataMatricesForATargetOtherClassifier(TEMP_IMG_OUTPUT_PATH, target, rotate)\n",
    "#     train_comp_name = [i[2] for i in train]\n",
    "#     print(\"3\")\n",
    "#     X = []\n",
    "#     Y = []\n",
    "#     for i in train:\n",
    "#         if i[0].shape!=():\n",
    "#             if i[2] not in test_comps:\n",
    "#                 X.append(i[0].flatten())\n",
    "#                 if i[1][0]==1:\n",
    "#                     Y.append(1)\n",
    "#                 else:\n",
    "#                     Y.append(0)\n",
    "#     X = np.array(X)\n",
    "\n",
    "\n",
    "#     test_comp_name = []\n",
    "#     test_y = []\n",
    "#     test_x = []\n",
    "#     for i in train:\n",
    "#         if i[0].shape != ():\n",
    "#             if i[2] in test_comps:\n",
    "#                 test_x.append(i[0].flatten())\n",
    "#                 test_comp_name.append(i[2])\n",
    "#                 if i[1][0]==1:\n",
    "#                     test_y.append(1)\n",
    "#                 else:\n",
    "#                     test_y.append(0)\n",
    "\n",
    "#     #print(len(X), len(test_y))\n",
    "#     clf = RandomForestClassifier(n_jobs=2)\n",
    "#     #print(len(X), len(Y))\n",
    "#     clf.fit(X, Y)\n",
    "#     y_rf_test_pred = clf.predict(test_x)\n",
    "#     print(\"Target:\\t{}\".format(target))\n",
    "#     str_preds = \"\"\n",
    "#     for ind in range(len(test_comp_name)):\n",
    "#         str_preds += test_comp_name[ind]\n",
    "#         if test_y[ind]==1 and y_rf_test_pred[ind]==1:\n",
    "#             str_preds += \",TP,ACT,1\"\n",
    "#         elif test_y[ind]==1 and y_rf_test_pred[ind]==0:\n",
    "#             str_preds += \",FN,ACT,0\"\n",
    "#         elif test_y[ind]==0 and y_rf_test_pred[ind]==0:\n",
    "#             str_preds += \",TN,INACT,0\"\n",
    "#         else:\n",
    "#             str_preds += \",FP,INACT,1\"\n",
    "#         str_preds += \"\\t\"\n",
    "\n",
    "#     print(\"RF Predictions:\")\n",
    "#     print(str_preds)\n",
    "\n",
    "#     svc = svm.SVC()\n",
    "#     svc.fit(X, Y)\n",
    "#     y_svc_test_pred = svc.predict(test_x)\n",
    "\n",
    "#     str_preds = \"\"\n",
    "\n",
    "#     for ind in range(len(test_comp_name)):\n",
    "#         str_preds += test_comp_name[ind]\n",
    "#         if test_y[ind]==1 and y_svc_test_pred[ind]==1:\n",
    "#             str_preds += \",TP,ACT,1\"\n",
    "#         elif test_y[ind]==1 and y_svc_test_pred[ind]==0:\n",
    "#             str_preds += \",FN,ACT,0\"\n",
    "#         elif test_y[ind]==0 and y_svc_test_pred[ind]==0:\n",
    "#             str_preds += \",TN,INACT,0\"\n",
    "#         else:\n",
    "#             str_preds += \",FP,INACT,1\"\n",
    "#         str_preds += \"\\t\"\n",
    "\n",
    "#     print(\"SVM Predictions:\")\n",
    "#     print(str_preds)\n",
    "\n",
    "\n",
    "#     lr = LogisticRegression()\n",
    "#     lr.fit(X, Y)\n",
    "#     y_lr_test_pred = lr.predict(test_x)\n",
    "\n",
    "#     str_preds = \"\"\n",
    "\n",
    "#     for ind in range(len(test_comp_name)):\n",
    "#         str_preds += test_comp_name[ind]\n",
    "#         if test_y[ind] == 1 and y_lr_test_pred[ind] == 1:\n",
    "#             str_preds += \",TP,ACT,1\"\n",
    "#         elif test_y[ind] == 1 and y_lr_test_pred[ind] == 0:\n",
    "#             str_preds += \",FN,ACT,0\"\n",
    "#         elif test_y[ind] == 0 and y_lr_test_pred[ind] == 0:\n",
    "#             str_preds += \",TN,INACT,0\"\n",
    "#         else:\n",
    "#             str_preds += \",FP,INACT,1\"\n",
    "#         str_preds += \"\\t\"\n",
    "#     print(\"LR Predictions:\")\n",
    "#     print(str_preds)\n",
    "\n",
    "#     print(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(target,accuracy_score(test_y, y_rf_test_pred), f1_score(test_y, y_rf_test_pred), matthews_corrcoef(test_y, y_rf_test_pred), accuracy_score(test_y, y_svc_test_pred), f1_score(test_y, y_svc_test_pred),\n",
    "#                               matthews_corrcoef(test_y, y_svc_test_pred), accuracy_score(test_y, y_lr_test_pred), f1_score(test_y, y_lr_test_pred),\n",
    "#                                           matthews_corrcoef(test_y, y_lr_test_pred)))\n",
    "\n",
    "        \n",
    "\n",
    "def trainModelECFP4Target(target):\n",
    "\n",
    "    model = None\n",
    "    test_comps = [\"CHEMBL286\"]\n",
    "\n",
    "    train = constructECFP4FeaturesVectors(target)\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "    train_comp_names = []\n",
    "    for i in train:\n",
    "        if i[0].shape!=():\n",
    "            if i[2] not in test_comps:\n",
    "                train_comp_names.append(i[2])\n",
    "                X.append(i[0])\n",
    "                if i[1][0]==1:\n",
    "                    Y.append(1)\n",
    "                else:\n",
    "                    Y.append(0)\n",
    "    X = X[:int(len(X)*0.64)]\n",
    "    Y = Y[:int(len(Y)*0.64)]\n",
    "    train_comp_names = train_comp_names[:int(len(train_comp_names)*0.64)]\n",
    "    X = np.array(X)\n",
    "    # print(train_comp_names)\n",
    "    # print(test_comps)\n",
    "    # print(set(train_comp_names)&set(test_comps))\n",
    "    test_comp_name = []\n",
    "    test_y = []\n",
    "    test_x = []\n",
    "    for i in train:\n",
    "        if i[0].shape != ():\n",
    "            if i[2] in test_comps:\n",
    "                test_x.append(i[0])\n",
    "                test_comp_name.append(i[2])\n",
    "                if i[1][0]==1:\n",
    "                    test_y.append(1)\n",
    "                else:\n",
    "                    test_y.append(0)\n",
    "\n",
    "\n",
    "    #print(len(X), len(test_y))\n",
    "    clf = RandomForestClassifier(n_jobs=2)\n",
    "    clf.fit(X, Y)\n",
    "    y_rf_test_pred = clf.predict(test_x)\n",
    "    tn_rf, fp_rf, fn_rf, tp_rf = confusion_matrix(test_y, y_rf_test_pred).ravel()\n",
    "    # print(len(test_x))\n",
    "    # print(\"Target:\\t{}\".format(target))\n",
    "    str_preds = \"\"\n",
    "    for ind in range(len(test_comp_name)):\n",
    "        str_preds += test_comp_name[ind]\n",
    "        if test_y[ind]==1 and y_rf_test_pred[ind]==1:\n",
    "            str_preds += \",TP,ACT,1\"\n",
    "        elif test_y[ind]==1 and y_rf_test_pred[ind]==0:\n",
    "            str_preds += \",FN,ACT,0\"\n",
    "        elif test_y[ind]==0 and y_rf_test_pred[ind]==0:\n",
    "            str_preds += \",TN,INACT,0\"\n",
    "        else:\n",
    "            str_preds += \",FP,INACT,1\"\n",
    "        str_preds += \"\\t\"\n",
    "    \"\"\"\n",
    "    print(\"RF Predictions:\")\n",
    "    print(str_preds)\n",
    "    \"\"\"\n",
    "    svc = svm.SVC()\n",
    "    svc.fit(X, Y)\n",
    "    y_svc_test_pred = svc.predict(test_x)\n",
    "    tn_svc, fp_svc, fn_svc, tp_svc = confusion_matrix(test_y, y_svc_test_pred).ravel()\n",
    "    str_preds = \"\"\n",
    "\n",
    "    for ind in range(len(test_comp_name)):\n",
    "        str_preds += test_comp_name[ind]\n",
    "        if test_y[ind]==1 and y_svc_test_pred[ind]==1:\n",
    "            str_preds += \",TP,ACT,1\"\n",
    "        elif test_y[ind]==1 and y_svc_test_pred[ind]==0:\n",
    "            str_preds += \",FN,ACT,0\"\n",
    "        elif test_y[ind]==0 and y_svc_test_pred[ind]==0:\n",
    "            str_preds += \",TN,INACT,0\"\n",
    "        else:\n",
    "            str_preds += \",FP,INACT,1\"\n",
    "        str_preds += \"\\t\"\n",
    "    \"\"\"\n",
    "    print(\"SVM Predictions:\")\n",
    "    print(str_preds)\n",
    "    \"\"\"\n",
    "\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X, Y)\n",
    "    y_lr_test_pred = lr.predict(test_x)\n",
    "    tn_lr, fp_lr, fn_lr, tp_lr = confusion_matrix(test_y, y_lr_test_pred).ravel()\n",
    "\n",
    "    str_preds = \"\"\n",
    "    #print(test_comp_name)\n",
    "    #print()\n",
    "    for ind in range(len(test_comp_name)):\n",
    "        str_preds += test_comp_name[ind]\n",
    "        if test_y[ind] == 1 and y_lr_test_pred[ind] == 1:\n",
    "            str_preds += \",TP,ACT,1\"\n",
    "        elif test_y[ind] == 1 and y_lr_test_pred[ind] == 0:\n",
    "            str_preds += \",FN,ACT,0\"\n",
    "        elif test_y[ind] == 0 and y_lr_test_pred[ind] == 0:\n",
    "            str_preds += \",TN,INACT,0\"\n",
    "        else:\n",
    "            str_preds += \",FP,INACT,1\"\n",
    "        str_preds += \"\\t\"\n",
    "    \"\"\"\n",
    "    print(\"LR Predictions:\")\n",
    "    print(str_preds)\n",
    "    \"\"\"\n",
    "    print(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(target,\n",
    "        accuracy_score(test_y, y_rf_test_pred), f1_score(test_y, y_rf_test_pred), matthews_corrcoef(test_y, y_rf_test_pred),\n",
    "        tn_rf, fp_rf, fn_rf, tp_rf,\n",
    "        accuracy_score(test_y, y_svc_test_pred), f1_score(test_y, y_svc_test_pred),matthews_corrcoef(test_y, y_svc_test_pred),\n",
    "        tn_svc, fp_svc, fn_svc, tp_svc,\n",
    "        accuracy_score(test_y, y_lr_test_pred), f1_score(test_y, y_lr_test_pred),matthews_corrcoef(test_y, y_lr_test_pred),\n",
    "        tn_lr, fp_lr, fn_lr, tp_lr))\n",
    "\n",
    "targets = [\"CHEMBL286\"]\n",
    "count  = 0\n",
    "for trgt in targets:\n",
    "    count+=1\n",
    "    eprint(count)\n",
    "    trainModelECFP4Target(trgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
