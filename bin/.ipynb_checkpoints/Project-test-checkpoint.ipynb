{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.getcwd() + '\\\\..')\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-2-712384b70b16>, line 30)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-712384b70b16>\"\u001b[0;36m, line \u001b[0;32m30\u001b[0m\n\u001b[0;31m    print(x.shape)\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from operator import itemgetter\n",
    "\n",
    "class CNNModel1(nn.Module):\n",
    "    def __init__(self, fully_layer_1, fully_layer_2, drop_rate):\n",
    "        super(CNNModel1, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 32, 2)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 2)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 2)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 64, 2)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.conv5 = nn.Conv2d(64, 32, 2)\n",
    "        self.bn5 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.drop_rate = drop_rate\n",
    "        self.fc1 = nn.Linear(32*5*5, fully_layer_1)\n",
    "        self.fc2 = nn.Linear(fully_layer_1, fully_layer_2)\n",
    "        self.fc3 = nn.Linear(fully_layer_2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         print(x.shape)\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "#         Â print(x.shape)\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "#         print(x.shape)\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "#         print(x.shape)\n",
    "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
    "#         print(x.shape)\n",
    "        x = self.pool(F.relu(self.bn5(self.conv5(x))))\n",
    "#         print(x.shape)\n",
    "\n",
    "        x = x.view(-1, 32*5*5)\n",
    "        x = F.dropout(F.relu(self.fc1(x)), self.drop_rate)\n",
    "        x = F.dropout(F.relu(self.fc2(x)), self.drop_rate)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# TODO: Create other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "torch.manual_seed(123)\n",
    "np.random.seed(123)\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "project_file_path = \"{}DEEPScreen\".format(os.getcwd().split(\"DEEPScreen\")[0])\n",
    "training_files_path = \"{}/training_files\".format(project_file_path)\n",
    "result_files_path = \"{}/result_files\".format(project_file_path)\n",
    "trained_models_path = \"{}/trained_models\".format(project_file_path)\n",
    "\n",
    "# training_files_path = \"training_files\"\n",
    "# result_files_path = \"result_files\"\n",
    "# trained_models_path = \"trained_models\"\n",
    "\n",
    "\n",
    "def save_best_model_predictions(experiment_name, epoch, validation_scores_dict, test_scores_dict, model, project_file_path, target_id, str_arguments,\n",
    "                                                                                   all_test_comp_ids, test_labels, test_predictions):\n",
    "\n",
    "    if not os.path.exists(os.path.join(trained_models_path, experiment_name)):\n",
    "        os.makedirs(os.path.join(trained_models_path, experiment_name))\n",
    "\n",
    "    torch.save(model.state_dict(),\n",
    "               \"{}/{}/{}_best_val-{}-state_dict.pth\".format(trained_models_path, experiment_name,\n",
    "                                                                               target_id, str_arguments))\n",
    "    # print(all_test_comp_ids)\n",
    "    str_test_predictions = \"CompoundID\\tLabel\\tPred\\n\"\n",
    "    for ind in range(len(all_test_comp_ids)):\n",
    "        str_test_predictions += \"{}\\t{}\\t{}\\n\".format(all_test_comp_ids[ind],\n",
    "                                                          test_labels[ind],\n",
    "                                                          test_predictions[ind])\n",
    "    best_test_performance_dict = test_scores_dict\n",
    "    best_test_predictions = str_test_predictions\n",
    "    return validation_scores_dict, best_test_performance_dict, best_test_predictions, str_test_predictions\n",
    "\n",
    "\n",
    "\n",
    "def get_device():\n",
    "    device = \"cpu\"\n",
    "    if use_gpu:\n",
    "        print(\"GPU is available on this device!\")\n",
    "        device = \"cuda\"\n",
    "    else:\n",
    "        print(\"CPU is available on this device!\")\n",
    "    return device\n",
    "\n",
    "\n",
    "def calculate_val_test_loss(model, criterion, data_loader, device):\n",
    "    total_count = 0\n",
    "    total_loss = 0.0\n",
    "    all_comp_ids = []\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    for i, data in enumerate(data_loader):\n",
    "        img_arrs, labels, comp_ids = data\n",
    "        img_arrs, labels = torch.tensor(img_arrs).type(torch.FloatTensor).to(device), torch.tensor(labels).to(device)\n",
    "        total_count += len(comp_ids)\n",
    "        y_pred = model(img_arrs).to(device)\n",
    "        loss = criterion(y_pred.squeeze(), labels)\n",
    "        total_loss += float(loss.item())\n",
    "        all_comp_ids.extend(list(comp_ids))\n",
    "        _, preds = torch.max(y_pred, 1)\n",
    "        all_labels.extend(list(labels))\n",
    "        all_predictions.extend(list(preds))\n",
    "\n",
    "\n",
    "    return total_loss, total_count, all_comp_ids, all_labels, all_predictions\n",
    "\n",
    "\n",
    "def train_validation_test_training(target_id, model_name, fully_layer_1, fully_layer_2, learning_rate, batch_size, drop_rate, n_epoch, experiment_name):\n",
    "    arguments = [str(argm) for argm in\n",
    "                 [target_id, model_name, fully_layer_1, fully_layer_2, learning_rate, batch_size, drop_rate, n_epoch, experiment_name]]\n",
    "\n",
    "    str_arguments = \"-\".join(arguments)\n",
    "    print(\"Arguments:\", str_arguments)\n",
    "\n",
    "    device = get_device()\n",
    "    exp_path = os.path.join(result_files_path, \"experiments\", experiment_name)\n",
    "\n",
    "    if not os.path.exists(exp_path):\n",
    "        os.makedirs(exp_path)\n",
    "\n",
    "    best_val_test_result_fl = open(\n",
    "        \"{}/best_val_test_performance_results-{}.txt\".format(exp_path,str_arguments), \"w\")\n",
    "    best_val_test_prediction_fl = open(\n",
    "        \"{}/best_val_test_predictions-{}.txt\".format(exp_path,str_arguments), \"w\")\n",
    "\n",
    "#     print(\"BEST F1\", best_val_test_result_fl, best_val_test_prediction_fl)\n",
    "    print(\"Fetching train loader\")\n",
    "    train_loader, valid_loader, test_loader = get_train_test_val_data_loaders(target_id, batch_size)\n",
    "    \n",
    "#     print(train_loader, valid_loader, test_loader)\n",
    "    \n",
    "    model = None\n",
    "    \n",
    "    if model_name == \"CNNModel1\":\n",
    "        model = CNNModel1(fully_layer_1, fully_layer_2, drop_rate).to(device)\n",
    "        \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    best_val_mcc_score, best_test_mcc_score = 0.0, 0.0\n",
    "    best_val_test_performance_dict = dict()\n",
    "    best_val_test_performance_dict[\"MCC\"] = 0.0\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        total_training_count = 0\n",
    "        total_training_loss = 0.0\n",
    "        print(\"Epoch :{}\".format(epoch))\n",
    "        model.train()\n",
    "        batch_number = 0\n",
    "        all_training_labels = []\n",
    "        all_training_preds = []\n",
    "        print(\"Training mode:\", model.training)\n",
    "        for i, data in enumerate(train_loader):\n",
    "            print(i, len(data))\n",
    "            batch_number += 1\n",
    "            # print(batch_number)\n",
    "            # clear gradient DO NOT forget you fool!\n",
    "            optimizer.zero_grad()\n",
    "            img_arrs, labels, comp_ids = data\n",
    "            img_arrs, labels = torch.tensor(img_arrs).type(torch.FloatTensor).to(device), torch.tensor(labels).to(device)\n",
    "\n",
    "            total_training_count += len(comp_ids)\n",
    "            y_pred = model(img_arrs).to(device)\n",
    "            _, preds = torch.max(y_pred, 1)\n",
    "            all_training_labels.extend(list(labels))\n",
    "            all_training_preds.extend(list(preds))\n",
    "\n",
    "            loss = criterion(y_pred.squeeze(), labels)\n",
    "            total_training_loss += float(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\"Epoch {} training loss:\".format(epoch), total_training_loss)\n",
    "        training_perf_dict = dict()\n",
    "        try:\n",
    "            training_perf_dict = prec_rec_f1_acc_mcc(all_training_labels, all_training_preds)\n",
    "        except:\n",
    "            print(\"There was a problem during training performance calculation!\")\n",
    "        # print(training_perf_dict)\n",
    "        model.eval()\n",
    "        with torch.no_grad():  # torch.set_grad_enabled(False):\n",
    "            print(\"Validation mode:\", not model.training)\n",
    "\n",
    "            total_val_loss, total_val_count, all_val_comp_ids, all_val_labels, val_predictions = calculate_val_test_loss(model, criterion, valid_loader, device)\n",
    "            \n",
    "            val_perf_dict = dict()\n",
    "            val_perf_dict[\"MCC\"] = 0.0\n",
    "            try:\n",
    "                val_perf_dict = prec_rec_f1_acc_mcc(all_val_labels, val_predictions)\n",
    "            except:\n",
    "                print(\"There was a problem during validation performance calculation!\")\n",
    "            \n",
    "\n",
    "            total_test_loss, total_test_count, all_test_comp_ids, all_test_labels, test_predictions = calculate_val_test_loss(\n",
    "                model, criterion, test_loader, device)\n",
    "            \n",
    "            test_perf_dict = dict()\n",
    "            test_perf_dict[\"MCC\"] = 0.0\n",
    "            try:\n",
    "                test_perf_dict = prec_rec_f1_acc_mcc(all_test_labels, test_predictions)\n",
    "            except:\n",
    "                print(\"There was a problem during test performance calculation!\")\n",
    "\n",
    "            if val_perf_dict[\"MCC\"] > best_val_mcc_score and test_perf_dict[\"MCC\"]> best_test_mcc_score:\n",
    "                best_val_mcc_score = val_perf_dict[\"MCC\"]\n",
    "                best_test_mcc_score = test_perf_dict[\"MCC\"]\n",
    "\n",
    "                validation_scores_dict, best_test_performance_dict, best_test_predictions, str_test_predictions = save_best_model_predictions(\n",
    "                    experiment_name, epoch, val_perf_dict, test_perf_dict,\n",
    "                    model,project_file_path, target_id, str_arguments,\n",
    "                    all_test_comp_ids, all_test_labels, test_predictions)\n",
    "\n",
    "        if epoch == n_epoch - 1:\n",
    "            score_list = get_list_of_scores()\n",
    "            for scr in score_list:\n",
    "                best_val_test_result_fl.write(\"Test {}:\\t{}\\n\".format(scr, best_test_performance_dict[scr]))\n",
    "            best_val_test_prediction_fl.write(best_test_predictions)\n",
    "\n",
    "            best_val_test_result_fl.close()\n",
    "            best_val_test_prediction_fl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validation_test_training(\"CHEMBL286\", \"CNNModel1\", 512, 256, 0.001, 32,\n",
    "                               0.25, 2, \"my_experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing import get_train_test_val_data_loaders\n",
    "from evaluation_metrics import prec_rec_f1_acc_mcc, get_list_of_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
